@inproceedings{Willich2020,
abstract = {Virtual Reality (VR) allows for infinitely large environments. However, the physical traversable space is always limited by real-world boundaries. This discrepancy between physical and virtual dimensions renders traditional locomotion methods used in real world unfeasible. To alleviate these limitations, research proposed various artificial locomotion concepts such as teleportation, treadmills, and redirected walking. However, these concepts occupy the user's hands, require complex hardware or large physical spaces. In this paper, we contribute nine VR locomotion concepts for foot-based locomotion, relying on the 3D position of the user's feet and the pressure applied to the sole as input modalities. We evaluate our concepts and compare them to state-of-the-art point {\&} teleport technique in a controlled experiment with 20 participants. The results confirm the viability of our approaches for foot-based and engaging locomotion. Further, based on the findings, we contribute a wireless hardware prototype implementation.},
author = {Willich, Julius Von and Schmitz, Martin and M{\"{u}}ller, Florian and Schmitt, Daniel and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems - CHI '20},
doi = {10.1145/3313831.3376626},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Honolulu, Chi - Unknown - Podoportation Foot-Based Locomotion in Virtual Reality.pdf:pdf},
isbn = {9781450367080},
keywords = {Foot-based input CCS Concepts •Human-centered comp,Interaction devices,Locomotion,User stud-ies,Virtual Reality},
mendeley-groups = {Diss{\_}myOther},
title = {{Podoportation: Foot-Based Locomotion in Virtual Reality}},
url = {https://dx.doi.org/10.1145/3313831.3376626},
volume = {20},
year = {2020}
}
@inproceedings{Gunther2020a,
abstract = {Haptic Feedback brings immersion and presence in Virtual Reality (VR) to the next level. While research proposes the usage of various tactile sensations, such as vibration or ultrasound approaches, the potential applicability of pressure feedback on the head is still under-explored. In this paper, we contribute concepts and design considerations for pressure-based feedback on the head through pneumatic actuation. As a proof-of-concept implementing our pressure-based haptics, we further present PneumoVolley: a VR experience similar to the classic Volleyball game but played with the head. In an exploratory user study with 9 participants, we evaluated our concepts and identified a significantly increased involvement compared to a no-haptics baseline along with high realism and enjoyment ratings using pressure-based feedback on the head in VR. LBW033, Page 1 CHI 2020 Late-Breaking Work},
author = {G{\"{u}}nther, Sebastian and Sch{\"{o}}n, Dominik and M{\"{u}}ller, Florian and M{\"{u}}hlh{\"{a}}user, Max and Schmitz, Martin},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems - CHI '20},
doi = {10.1145/3334480.3382916},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\"{u}}nther et al. - Unknown - PneumoVolley Pressure-based Haptic Feedback on the Head through Pneumatic Actuation.pdf:pdf},
isbn = {9781450368193},
keywords = {2020,April 25-30,CCS Concepts •Human-centered computing → Human com,CHI 2020,HI,Haptic devices,Haptics,Honolulu,Pressure Feedback,USA Author Keywords Virtual Reality,User studies,Volleyball},
mendeley-groups = {Diss{\_}myOther},
title = {{PneumoVolley: Pressure-based Haptic Feedback on the Head through Pneumatic Actuation}},
url = {https://doi.org/10.1145/3334480.3382916},
year = {2020}
}
@inproceedings{Gunther2020,
abstract = {Figure 1. Therminator concepts and example VR applications showing (a) a user during our experiment with a snow visual stimulus, (b) a cold game environment with a user throwing snowballs, (c) a warm tropical islands, and (d) a firefighting simulation with a user extinguishing flames. ABSTRACT Recent advances have made Virtual Reality (VR) more realistic than ever before. This improved realism is attributed to to-day's ability to increasingly appeal to human sensations, such as visual, auditory or tactile. While research also examines temperature sensation as an important aspect, the interdepen-dency of visual and thermal perception in VR is still underex-plored. In this paper, we propose Therminator, a thermal display concept that provides warm and cold on-body feedback in VR through heat conduction of flowing liquids with different temperatures. Further, we systematically evaluate the interdependency of different visual and thermal stimuli on the temperature perception of arm and abdomen with 25 participants. As part of the results, we found varying temperature perception depending on the stimuli, as well as increasing involvement of users during conditions with matching stimuli.},
author = {G{\"{u}}nther, Sebastian and Elmoghazy, Omar and M{\"{u}}ller, Florian and M{\"{u}}hlh{\"{a}}user, Max and Sch{\"{o}}n, Dominik and Schmitz, Martin},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems - CHI '20},
doi = {10.1145/3313831.3376195},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Honolulu, Chi - Unknown - Therminator Understanding the Interdependency of Visual and On-Body Thermal Feedback in Virtual Reality.pdf:pdf},
isbn = {9781450367080},
keywords = {Author Keywords Haptics,Haptic devices,Temperature,Thermal Feedback,User studies,Virtual Reality CCS Concepts •Human-centered compu},
mendeley-groups = {Diss{\_}myOther},
pages = {1--14},
title = {{Therminator : Understanding the Interdependency of Visual and On-Body Thermal Feedback in Virtual Reality}},
url = {http://dx.doi.org/10.1145/3313831.3376195},
volume = {20},
year = {2020}
}
@incollection{Muller2020c,
address = {Bonn},
author = {M{\"{u}}ller, Florian},
booktitle = {Ausgezeichnete Informatikdissertationen 2019 (to appear)},
mendeley-groups = {Diss{\_}myOther},
publisher = {Gesellschaft f{\"{u}}r Informatik e.V.},
title = {{Around-Body Interaction: {\"{U}}ber die Nutzung der Bewegungen von Gliedma{\ss}en zur Interaktion in einer digital erweiterten physischen Welt}},
year = {2020}
}
@article{Muller2020a,
author = {M{\"{u}}ller, Florian and G{\"{u}}nther, Sebastian and M{\"{u}}hlh{\"{a}}user, Max},
doi = {10.1109/MPRV.2020.2977850},
journal = {IEEE Pervasive Computing (to appear)},
mendeley-groups = {Diss{\_}myOther},
number = {2},
title = {{Around-body Interaction: Interacting While on the Go}},
volume = {19},
year = {2020}
}
@inproceedings{Muller2020,
abstract = {Recent technological advances have made head-mounted displays (HMDs) smaller and untethered, fostering the vision of ubiquitous interaction in a digitally augmented physical world. Consequently, a major part of the interaction with such devices will happen on the go, calling for interaction techniques that allow users to interact while walking. In this paper, we explore lateral shifts of the walking path as a hands-free input modality. The available input options are visualized as lanes on the ground parallel to the user's walking path. Users can select options by shifting the walking path sideways to the respective lane. We contribute the results of a controlled experiment with 18 participants, confirming the viability of our approach for fast, accurate, and joyful interactions. Further, based on the findings of the controlled experiment, we present three example applications.},
address = {Honolulu, HI, USA},
author = {M{\"{u}}ller, Florian and Schmitt, Daniel and G{\"{u}}nther, Sebastian and Schmitz, Martin and Funk, Markus and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems - CHI '20},
doi = {10.1145/3313831.3376852},
mendeley-groups = {Diss{\_}MyRelevant,Cheesyfoot2go/Relevant Own Pubs},
publisher = {ACM},
title = {{Walk The Line: Leveraging Lateral Shifts of the Walking Path as an Input Modality for Head-Mounted Displays}},
year = {2020}
}
@book{Mueller_Diss_published,
address = {Darmstadt},
author = {M{\"{u}}ller, Florian},
doi = {10.25534/tuprints-00011388},
isbn = {9783750277618},
publisher = {TUprints},
title = {{Around-Body Interaction: Leveraging Limb-movements for Interacting in a Digitally Augmented Physical World}},
url = {http://tuprints.ulb.tu-darmstadt.de/11388/},
year = {2020}
}
@inproceedings{Funk2019,
abstract = {Figure 1: A user is teleporting herself in a Virtual Environment using the Curved Teleport. It allows her to teleport around an obstacle and graphically choose the orientation, which she wants to face after teleportation only by using the curved trajectory visualization with orientation indication, and without having to turn her body in the physical world. ABSTRACT Room-scale Virtual Reality (VR) systems have arrived in users' homes where tracked environments are set up in limited physical spaces. As most Virtual Environments (VEs) are larger than the tracked physical space, locomotion techniques are used to navigate in VEs. Currently, in recent VR games, point {\&} teleport is the most popular locomotion technique. However, it only allows users to select the position of the teleportation and not the orientation that the user is facing after the teleport. This results in users having to manually correct their orientation after teleporting and possibly getting entangled by the cable of the headset. In this paper, we introduce and evaluate three diferent point {\&} teleport techniques that enable users to specify the target orientation while teleporting. The results show that, although the three teleportation techniques with orientation indication increase the average teleportation time, they lead to a decreased need for correcting the orientation after teleportation.},
address = {Glasgow, Scotland, UK},
author = {Funk, Markus and M{\"{u}}ller, Florian and Fendrich, Marco and Shene, Megan and Kolvenbach, Moritz and Dobbertin, Niclas and G{\"{u}}nther, Sebastian and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI '19},
doi = {10.1145/3290605.3300377},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Funk et al. - 2019 - Assessing the Accuracy of Point {\&}amp Teleport Locomotion with Orientation Indication for Virtual Reality using Curv.pdf:pdf},
isbn = {9781450359702},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
pages = {12},
publisher = {ACM},
title = {{Assessing the Accuracy of Point {\&} Teleport Locomotion with Orientation Indication for Virtual Reality using Curved Trajectories}},
url = {https://doi.org/10.1145/3290605.3300377},
year = {2019}
}
@inproceedings{VonWillich2019,
abstract = {Locomotion in Virtual Reality (VR) is an important topic as there is a mismatch between the size of a Virtual Environment and the physically available tracking space. Although many locomotion techniques have been proposed, research on VR locomotion has not concluded yet. In this demonstration, we contribute to the area of VR locomotion by introducing VRChairRacer. VRChairRacer introduces a novel mapping the velocity of a racing cart on the backrest of an office chair. Further, it maps a users' rotation onto the steering of a virtual racing cart. VRChairRacer demonstrates this locomotion technique to the community through an immersive multiplayer racing demo.},
address = {Glasgow, Scotland, UK},
author = {von Willich, Julius and Sch{\"{o}}n, Dominik and G{\"{u}}nther, Sebastian and M{\"{u}}ller, Florian and M{\"{u}}hlh{\"{a}}user, Max and Funk, Markus},
booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems - CHI '19},
doi = {10.1145/3290607.3313254},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/von Willich et al. - 2019 - VRChairRacer Using an Office Chair Backrest as a Locomotion Technique for VR Racing Games.pdf:pdf},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
title = {{VRChairRacer: Using an Office Chair Backrest as a Locomotion Technique for VR Racing Games}},
url = {https://doi.org/10.1145/3290607.3313254},
year = {2019}
}
@inproceedings{Gunther2019,
abstract = {With emerging trends of notifying persons through ubiquitous technologies [2], such as ambient light, vibrotactile, or auditory cues, none of these technologies are truly ubiquitous and have proven to be easily missed or ignored. In this work, we propose Slappyfications, a novel way of sending unmissable embodied and ubiquitous notifications through a palm-based interface [1]. Our prototype enables the users to send three types of Slappyfications: poke, slap, and the STEAM-HAMMER. Through a Wizard-of-Oz study, we show the applicability of our system in real-world scenarios. The results reveal a promising trend, as none of the participants missed a single Slappyfication.},
address = {Glasgow, Scotland, UK},
author = {G{\"{u}}nther, Sebastian and M{\"{u}}ller, Florian and Funk, Markus and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems - CHI '19},
doi = {10.1145/3290607.3311780},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\"{u}}nther et al. - 2019 - Slappyfications Towards Ubiquitous Physical and Embodied Notifications.pdf:pdf},
isbn = {9781450359719},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
title = {{Slappyfications: Towards Ubiquitous Physical and Embodied Notifications}},
url = {https://doi.org/10.1145/3290607.3311780},
year = {2019}
}
@inproceedings{SchmitzMartinStitzFlorianMuller2019,
abstract = {Hover, touch, and force are promising input modalities that get increasingly integrated into screens and everyday objects. However, these interactions are often limited to fat surfaces and the integration of suitable sensors is time-consuming and costly. To alleviate these limitations, we contribute Tri-laterate: A fabrication pipeline to 3D print custom objects that detect the 3D position of a fnger hovering, touching, or forcing them by combining multiple capacitance measurements via capacitive trilateration. Trilaterate places and routes actively-shielded sensors inside the object and operates on consumer-level 3D printers. We present technical evaluations and example applications that validate and demonstrate the wide applicability of Trilaterate. CCS CONCEPTS • Human-centered computing → Interaction devices; • Hardware → Tactile and hand-based interfaces;},
address = {New York, New York, USA},
author = {Schmitz, Martin and Stitz, Martin and M{\"{u}}ller, Florian and Funk, Markus and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI '19},
doi = {10.1145/3290605.3300684},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schmitz et al. - 2019 - .trilaterate A Fabrication Pipeline to Design and 3D Print Hover-, Touch-, and Force-Sensitive Objects.pdf:pdf},
isbn = {9781450359702},
keywords = {3D printing,capacitive sensing,force,hover,touch},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
pages = {1--13},
publisher = {ACM Press},
title = {{./trilaterate: A Fabrication Pipeline to Design and 3D Print Hover-, Touch-, and Force-Sensitive Objects}},
url = {https://doi.org/10.1145/3290605.3300684 http://dl.acm.org/citation.cfm?doid=3290605.3300684},
year = {2019}
}
@article{Gunther2019,
address = {New York, New York, USA},
author = {G{\"{u}}nther, Sebastian and Makhija, Mohit and M{\"{u}}ller, Florian and Sch{\"{o}}n, Dominik and M{\"{u}}hlh{\"{a}}user, Max and Funk, Markus},
doi = {10.1145/3322276.3322302},
isbn = {9781450358507},
journal = {Proceedings of the 2019 on Designing Interactive Systems Conference - DIS '19},
pages = {227--240},
publisher = {ACM Press},
title = {{PneumAct: Pneumatic Kinesthetic Actuation of Body Joints in Virtual Reality Environments}},
url = {http://dl.acm.org/citation.cfm?doid=3322276.3322302},
year = {2019}
}
@inproceedings{Marky2019,
abstract = {{\textcopyright} 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. Over the last decades, E-learning has gained a lot of popularity and enabled students to learn in front of their computers using Internet-based learning systems rather than physically attending lectures. Those E-learning systems are different from traditional learning and do not fully immerse the student in the learning environment. Thus, we propose Teachyverse, an immersive VR lecture hall that combines e-learning, traditional learning, and remote collaboration. Teachyverse immerses the student in a virtual lecture hall. A proof-of-concept study shows that students perceive lectures in Teachyverse as fun and would like to use Teachyverse as a further E-Learning option.},
author = {Marky, K. and M{\"{u}}ller, F. and Funk, M. and Gei{\ss}, A. and G{\"{u}}nther, S. and Schmitz, M. and Riemann, J. and M{\"{u}}hlh{\"{a}}user, M.},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3340764.3344917},
isbn = {9781450371988},
keywords = {E-Learning,Lecture halls,Virtual Lecture,Virtual Reality},
title = {{Teachyverse: Collaborative e-learning in virtual reality lecture halls}},
year = {2019}
}
@article{VonWillich2019,
address = {New York, New York, USA},
author = {von Willich, Julius and Funk, Markus and M{\"{u}}ller, Florian and Marky, Karola and Riemann, Jan and M{\"{u}}hlh{\"{a}}user, Max},
doi = {10.1145/3322276.3322334},
isbn = {9781450358507},
journal = {Proceedings of the 2019 on Designing Interactive Systems Conference  - DIS '19},
pages = {487--496},
publisher = {ACM Press},
title = {{You Invaded my Tracking Space! Using Augmented Virtuality for Spotting Passersby in Room-Scale Virtual Reality}},
url = {http://dl.acm.org/citation.cfm?doid=3322276.3322334},
year = {2019}
}
@inproceedings{Distante2019,
abstract = {Workshops are a great opportunity for identifying innovative topics of research that might require discussion and maturation. This paper summarizes the outcomes of the workshops track of the 11th Engineering Interactive Computing Systems conference (EICS 2019), held in Valencia (Spain) on 18-21 June 2019. The track featured three workshops, one half-day, one full-day and one two-days workshop, each focused on specific topics of the ongoing research in engineering usable and effective interactive computing systems. In particular, the list of discussed topics include novel forms of interaction and emerging themes in HCI related to new application domains, more efficient and enjoyable interaction possibilities associated to smart objects and smart environments, challenges faced in designing, developing and using interactive systems involving multiple stakeholders.},
author = {Distante, Damiano and Winckler, Marco and Bernhaupt, Regina and Bowen, Judy and Campos, Jos{\'{e}} Creissac and M{\"{u}}ller, Florian and Palanque, Philippe and {Van Den Bergh}, Jan and Weyers, Benjamin and Voit, Alexandra},
booktitle = {Proceedings of the ACM SIGCHI Symposium on Engineering Interactive Computing Systems, EICS 2019},
doi = {10.1145/3319499.3335655},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Distante et al. - Unknown - Trends on Engineering Interactive Systems an overview of works presented in workshops at EICS 2019.pdf:pdf},
isbn = {9781450367455},
keywords = {Enabling tecnhologies,Engineering interactive systems,HCI,Multimodal interaction,Multiple stakeholders,Smart environments,Smart objects},
title = {{Trends on engineering interactive systems: An overview of works presented in workshops at EICS 2019}},
url = {https://doi.org/10.1145/3319499.3335655},
year = {2019}
}
@inproceedings{Muller2019,
address = {New York, New York, USA},
author = {M{\"{u}}ller, Florian and McManus, Joshua and G{\"{u}}nther, Sebastian and Schmitz, Martin and M{\"{u}}hlh{\"{a}}user, Max and Funk, Markus},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI '19},
doi = {10.1145/3290605.3300707},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{u}}ller et al. - 2019 - Mind the Tap Assessing Foot-Taps for Interacting with Head-Mounted Displays.pdf:pdf},
isbn = {9781450359702},
keywords = {all or part of,foot interaction,hmd,human factors,is granted without fee,or hard copies of,permission to make digital,personal or classroom use,provided that copies,this work for,user study},
mendeley-groups = {Cheesyfoot2go,Diss{\_}MyRelevant,First Author Papers,Cheesyfoot2go/Relevant Own Pubs},
pages = {1--13},
publisher = {ACM Press},
title = {{Mind the Tap: Assessing Foot-Taps for Interacting with Head-Mounted Displays}},
url = {http://dl.acm.org/citation.cfm?doid=3290605.3300707},
year = {2019}
}
@inproceedings{muller2018camea,
address = {New York, New York, USA},
author = {M{\"{u}}ller, Florian and Barnikol, Maximilian and Funk, Markus and Schmitz, Martin and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 11th PErvasive Technologies Related to Assistive Environments Conference on - PETRA '18},
doi = {10.1145/3197768.3201569},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{u}}ller et al. - 2018 - CaMea Camera-Supported Workpiece Measurement for CNC Milling Machines.pdf:pdf},
isbn = {9781450363907},
mendeley-groups = {First Author Papers,My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
organization = {ACM},
pages = {345--350},
publisher = {ACM Press},
title = {{CaMea: Camera-Supported Workpiece Measurement for CNC Milling Machines}},
url = {http://dl.acm.org/citation.cfm?doid=3197768.3201569},
year = {2018}
}
@inproceedings{murauer2018analysis,
address = {New York, New York, USA},
author = {Murauer, Nela and M{\"{u}}ller, Florian and G{\"{u}}nther, Sebastian and Sch{\"{o}}n, Dominik and Pflanz, Nerina and Funk, Markus},
booktitle = {Proceedings of the 11th PErvasive Technologies Related to Assistive Environments Conference on - PETRA '18},
doi = {10.1145/3197768.3201570},
isbn = {9781450363907},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
organization = {ACM},
pages = {351--357},
publisher = {ACM Press},
title = {{An Analysis of Language Impact on Augmented Reality Order Picking Training}},
url = {http://dl.acm.org/citation.cfm?doid=3197768.3201570},
year = {2018}
}
@book{SmartObjects2018,
address = {Aachen},
booktitle = {6th Workshop on Interacting with Smart Objects (SmartObjects)},
editor = {M{\"{u}}ller, Florian and Schnelle-Walka, Dirk and G{\"{u}}nther, Sebastian and Funk, Markus},
issn = {1613-0073},
mendeley-groups = {Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
number = {2082},
publisher = {CEUR-WS},
series = {CEUR Workshop Proceedings},
title = {{Proceedings of the 6th Workshop on Interacting with Smart Objects (SmartObjects)}},
url = {http://ceur-ws.org/Vol-2082/},
year = {2018}
}
@inproceedings{muller2018smartobjects,
abstract = {Smart objects are everyday objects that have computing capabilities and give rise to new ways of interaction with our environment. The increasing number of smart objects in our life shapes how we interact beyond the desktop. In this workshop we explore various aspects of the design, development and deployment of smart objects including how one can interact with smart objects.},
address = {New York, New York, USA},
author = {M{\"{u}}ller, Florian and Schnelle-Walka, Dirk and Grosse-Puppendahl, Tobias and G{\"{u}}nther, Sebastian and Funk, Markus and Luyten, Kris and Brdiczka, Oliver and Dezfuli, Niloofar and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems - CHI '18},
doi = {10.1145/3170427.3170606},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{u}}ller et al. - 2018 - SmartObjects Sixth Workshop on Interacting with Smart Objects.pdf:pdf},
isbn = {9781450356213},
keywords = {softwarecampus},
mendeley-groups = {First Author Papers,My Publications,SmartObjects'19,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
mendeley-tags = {softwarecampus},
organization = {ACM},
pages = {1--6},
publisher = {ACM Press},
title = {{SmartObjects: Sixth Workshop on Interacting with Smart Objects}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84875839487{\&}partnerID=40{\&}md5=a960b66ce19563e939fd5f9428864c17 http://dl.acm.org/citation.cfm?doid=2451176.2451227 http://dl.acm.org/citation.cfm?doid=3170427.3170606},
year = {2018}
}
@inproceedings{Meurisch2018,
address = {New York, New York, USA},
author = {Meurisch, Christian and M{\"{u}}hlh{\"{a}}user, Max and Scholl, Philipp M. and Naeem, Usman and Pejovi{\'{c}}, Veljko and M{\"{u}}ller, Florian and {Di Lascio}, Elena and Kuo, Pei-Yi Patricia and Kauschke, Sebastian and Azam, Muhammad Awais},
booktitle = {Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers - UbiComp '18},
doi = {10.1145/3267305.3274133},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Meurisch et al. - 2018 - UPA'18 3rd International Workshop on Ubiquitous Personal Assistance.pdf:pdf},
isbn = {9781450359665},
keywords = {anticipatory mobile computing,digital personal assistants,personalization,proactive support,ubiquitous devices},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
pages = {766--769},
publisher = {ACM Press},
title = {{UPA'18: 3rd International Workshop on Ubiquitous Personal Assistance}},
url = {http://dl.acm.org/citation.cfm?doid=3267305.3274133},
year = {2018}
}
@inproceedings{gunther2018tactileglove,
address = {New York, New York, USA},
author = {G{\"{u}}nther, Sebastian and M{\"{u}}ller, Florian and Funk, Markus and Kirchner, Jan and Dezfuli, Niloofar and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 11th PErvasive Technologies Related to Assistive Environments Conference on - PETRA '18},
doi = {10.1145/3197768.3197785},
isbn = {9781450363907},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
organization = {ACM},
pages = {273--280},
publisher = {ACM Press},
title = {{TactileGlove: Assistive Spatial Guidance in 3D Space through Vibrotactile Navigation}},
url = {http://dl.acm.org/citation.cfm?doid=3197768.3197785},
year = {2018}
}
@inproceedings{muller2018personalized,
address = {New York, New York, USA},
author = {M{\"{u}}ller, Florian and Schmitz, Martin and Funk, Markus and G{\"{u}}nther, Sebastian and Dezfuli, Niloofar and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems - CHI '18},
doi = {10.1145/3170427.3188661},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{u}}ller et al. - 2018 - Personalized User-Carried Single Button Interfaces as Shortcuts for Interacting with Smart Devices.pdf:pdf},
isbn = {9781450356213},
keywords = {human factors,interaction,smart devices},
mendeley-groups = {First Author Papers,My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
organization = {ACM},
pages = {1--6},
publisher = {ACM Press},
title = {{Personalized User-Carried Single Button Interfaces as Shortcuts for Interacting with Smart Devices}},
url = {http://doi.acm.org/10.1145/3170427.3188661{\%}0Ahttp://dl.acm.org/citation.cfm?doid=3170427.3188661 http://dl.acm.org/citation.cfm?doid=3170427.3188661},
year = {2018}
}
@inproceedings{gunther2018checkmate,
address = {New York, New York, USA},
author = {G{\"{u}}nther, Sebastian and M{\"{u}}ller, Florian and Schmitz, Martin and Riemann, Jan and Dezfuli, Niloofar and Funk, Markus and Sch{\"{o}}n, Dominik and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems - CHI '18},
doi = {10.1145/3170427.3188647},
isbn = {9781450356213},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
organization = {ACM},
pages = {1--6},
publisher = {ACM Press},
title = {{CheckMate: Exploring a Tangible Augmented Reality Interface for Remote Interaction}},
url = {http://dl.acm.org/citation.cfm?doid=3170427.3188647},
year = {2018}
}
@inproceedings{schnelle2017smartobjects,
abstract = {Smart objects are everyday objects that have computing capabilities and give rise to new ways of interaction with our environment. The increasing number of smart objects in our life shapes how we interact beyond the desktop. In this workshop we explore various aspects of the design, development and deployment of smart objects including how one can interact with smart objects.},
address = {New York, New York, USA},
author = {Schnelle-Walka, Dirk and M{\"{u}}ller, Florian and Grosse-Puppendahl, Tobias and Luyten, Kris and M{\"{u}}hlh{\"{a}}user, Max and Brdiczka, Oliver},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion - IUI '17 Companion},
doi = {10.1145/3030024.3040249},
isbn = {9781450348935},
keywords = {softwarecampus},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
mendeley-tags = {softwarecampus},
organization = {ACM},
pages = {21--23},
publisher = {ACM Press},
title = {{SmartObjects: Fifth Workshop on Interacting with Smart Objects}},
url = {http://dl.acm.org/citation.cfm?doid=3030024.3040249},
year = {2017}
}
@inproceedings{gunther2017byo,
abstract = {Sharing and manipulating information are essential for collaborative work in meeting scenarios. Nowadays, people tend to bring their own devices as a result of increasing mobility possibilities. However, transferring data from one device to another can be cumbersome and tedious if restrictions like different platforms, form factors or environmental limitations apply. In this paper, we present two concepts to enrich interaction on and between devices through 3D printed customized tangibles: 1) Bring your own information, and 2) bring your own tools. For this, we enable interactivity for low-cost and passive tangible 3D printed objects by adding conductive material and make use of touch-enabled surfaces. Our system allows users to easily share digital contents across various devices and to manipulate them with individually designed tools without additional hardware required. Copyright {\textcopyright} 2017 ACM.},
address = {New York, New York, USA},
author = {G{\"{u}}nther, Sebastian and Schmitz, Martin and M{\"{u}}ller, Florian and Riemann, Jan and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 2017 ACM Workshop on Interacting with Smart Objects - SmartObject '17},
doi = {10.1145/3038450.3038456},
isbn = {9781450349024},
keywords = {3D printing,Capacitive sensing,Data manipulation,Data sharing,Data visualization,Digital fabrication,Input sensing,Rapid prototyping,capacitive sensing,data manipulation,data sharing,data visualization,digital fabrication,input sensing,rapid prototyping,softwarecampus},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
mendeley-tags = {softwarecampus},
organization = {ACM},
pages = {21--26},
publisher = {ACM Press},
title = {{BYO*: Utilizing 3D Printed Tangible Tools for Interaction on Interactive Surfaces}},
url = {http://dl.acm.org/citation.cfm?doid=3038450.3038456{\%}0Ahttp://doi.acm.org/10.1145/3038450.3038456 http://dl.acm.org/citation.cfm?doid=3038450.3038456},
year = {2017}
}
@inproceedings{riemann2017evaluation,
abstract = {{\textcopyright} 2017 Copyright held by the owner/author(s). Stacking is a common practice of organizing documents in the physical world. With the recent advent of interactive tabletops, physical documents can now coexist with digital documents on the same surface. As a result, systems were developed and studied which allow piling of both types of documents with the physical documents being placed on top of the digital ones. In this paper, we study the concept of true hybrid stacking, allowing users to stack both types of documents in an arbitrary order using a hybrid tabletop system called StackTop. We discuss the results and derive implications for future hybrid tabletop systems with stacking support.},
address = {New York, New York, USA},
author = {Riemann, Jan and M{\"{u}}ller, Florian and G{\"{u}}nther, Sebastian and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 2017 ACM Workshop on Interacting with Smart Objects - SmartObject '17},
doi = {10.1145/3038450.3038451},
isbn = {9781450349024},
keywords = {Hybrid physical-digital interaction,Interactive tabletop displays,Multitouch,Peripheral displays,Piling,Stacking,softwarecampus},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
mendeley-tags = {softwarecampus},
organization = {ACM},
pages = {13--20},
publisher = {ACM Press},
title = {{An Evaluation of Hybrid Stacking on Interactive Tabletops}},
url = {http://dl.acm.org/citation.cfm?doid=3038450.3038451},
year = {2017}
}
@book{Schnelle-Walka2017,
editor = {Schnelle-Walka, Dirk and M{\"{u}}ller, Florian},
isbn = {9781450349024},
mendeley-groups = {Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
pages = {38},
publisher = {ACM},
title = {{Proceedings of the 2017 ACM Workshop on Interacting with Smart Objects}},
url = {https://dl.acm.org/citation.cfm?id=3038450},
year = {2017}
}
@inproceedings{muller2017cloudbits,
abstract = {{\textcopyright} 2017 Copyright held by the owner/author(s). The retrieval of additional information from public (e.g., map data) or private (e.g., e-mail) information sources using personal smart devices is a common habit in today's co-located conversations. This behavior of users imposes challenges in two main areas: 1) cognitive focus switching and 2) information sharing.},
address = {New York, New York, USA},
author = {M{\"{u}}ller, Florian and G{\"{u}}nther, Sebastian and Nejad, Azita Hosseini and Dezfuli, Niloofar and Khalilbeigi, Mohammadreza and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 5th Symposium on Spatial User Interaction - SUI '17},
doi = {10.1145/3131277.3132173},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{u}}ller et al. - 2017 - Cloudbits supporting conversations through augmented zero-query search visualization.pdf:pdf},
isbn = {9781450354868},
keywords = {-  Human-centered computing  -{\textgreater}  Mixed / augmented,Collaborative interaction,Design,HMD,Human Factors,softwarecampus},
mendeley-groups = {Diss{\_}MyRelevant,First Author Papers,Cheesyfoot2go/Relevant Own Pubs,My Publications},
mendeley-tags = {softwarecampus},
organization = {ACM},
pages = {30--38},
publisher = {ACM Press},
title = {{Cloudbits: supporting conversations through augmented zero-query search visualization}},
url = {https://doi.org/10.1145/3131277.3132173 http://dl.acm.org/citation.cfm?doid=3131277.3132173},
volume = {17},
year = {2017}
}
@inproceedings{schmitz2016liquido,
abstract = {Tilting and motion are widely used as interaction modalities in smart objects such as wearables and smart phones (e.g., to detect posture or shaking). They are often sensed with accelerometers. In this paper, we propose to embed liquids into 3D printed objects while printing to sense various tilting and motion interactions via capacitive sensing. This method reduces the assembly effort after printing and is a low-cost and easy-to-apply way of extending the input capabilities of 3D printed objects. We contribute two liquid sensing patterns and a practical printing process using a standard dual-extrusion 3D printer and commercially available materials. We validate the method by a series of evaluations and provide a set of interactive example applications. {\textcopyright} 2016 Authors.},
address = {New York, New York, USA},
author = {Schmitz, Martin and Leister, Andreas and Dezfuli, Niloofar and Riemann, Jan and M{\"{u}}ller, Florian and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA '16},
doi = {10.1145/2851581.2892275},
isbn = {9781450340823},
keywords = {3D printing,capacitive sensing,digital fabrication,input sensing,interaction devices,motion,printed electronics,rapid prototyping,tilting},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
organization = {ACM},
pages = {2688--2696},
publisher = {ACM Press},
title = {{Liquido: Embedding Liquids into 3D Printed Objects to Sense Tilting and Motion}},
url = {http://dx.doi.org/10.1145/2851581.2892275{\%}0Ahttp://dl.acm.org/citation.cfm?doid=2851581.2892275 http://dl.acm.org/citation.cfm?doid=2851581.2892275},
year = {2016}
}
@inproceedings{schnelle2016scwt,
abstract = {The increasing number of smart objects in our everyday life shapes how we interact beyond the desktop. In this workshop we discuss how advanced interactions with smart objects in the context of the Internet-of-Thingsshould be designed from various perspectives, such as HCI and AI as well as industry and academia.},
address = {New York, New York, USA},
author = {Schnelle-Walka, Dirk and M{\"{u}}hlh{\"{a}}user, Max and Limonad, Lior and Grosse-Puppendahl, Tobias and Lanir, Joel and M{\"{u}}ller, Florian and Mecella, Massimo and Luyten, Kris and Kuflik, Tsvi and Brdiczka, Oliver},
booktitle = {Companion Publication of the 21st International Conference on Intelligent User Interfaces - IUI '16 Companion},
doi = {10.1145/2876456.2882849},
isbn = {9781450341400},
mendeley-groups = {My Publications,SmartObjects'19,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
organization = {ACM},
pages = {3--5},
publisher = {ACM Press},
title = {{SCWT: A Joint Workshop on Smart Connected and Wearable Things}},
url = {http://dl.acm.org/citation.cfm?doid=2876456.2882849},
year = {2016}
}
@inproceedings{riemann2016freetop,
abstract = {Augmenting the physical world using projection technologies or head-worn displays becomes increasingly popular in research and commercial applications. However, a common problem is interference between the physical surface's texture and the projection. In this paper, we present FreeTop, a combined approach to finding areas suitable for projection, which considers multiple aspects influencing projection quality, like visual texture and physical surface structure. FreeTop can be used in stationary and mobile settings for locating free areas in arbitrary physical settings suitable for projective augmentation and touch interaction.},
address = {New York, New York, USA},
author = {Riemann, Jan and Khalilbeigi, Mohammadreza and Schmitz, Martin and Doeweling, Sebastian and M{\"{u}}ller, Florian and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA '16},
doi = {10.1145/2851581.2892321},
isbn = {9781450340823},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
organization = {ACM},
pages = {1598--1606},
publisher = {ACM Press},
title = {{FreeTop: Finding Free Spots for Projective Augmentation}},
url = {http://dl.acm.org/citation.cfm?doid=2851581.2892321},
year = {2016}
}
@inproceedings{muller2016proxiwatch,
abstract = {Smartwatches allow ubiquitous and mobile interaction with digital contents. Because of the small screen sizes, tradi-tional interaction techniques are often not applicable. In this work, we show how the degree of freedom offered by the elbow joint, i.e., flexion and extension, can be leveraged as an additional one-handed input modality for smartwatches. By moving the watch towards or away from the body, the user is able to provide input to the smartwatch without a second hand. We present the results of a controlled ex-periment focusing on the human capabilities for proximity-based interaction. Based on the results, we propose guide-lines for designing proximity-based smartwatch interfaces and present ProxiWatch: a one-handed and proximity-based input modality for smartwatches alongside a proto-typical implementation.},
address = {New York, New York, USA},
author = {M{\"{u}}ller, Florian and G{\"{u}}nther, Sebastian and Dezfuli, Niloofar and Khalilbeigi, Mohammadreza and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA '16},
doi = {10.1145/2851581.2892450},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{u}}ller et al. - 2016 - ProxiWatch Enhancing smartwatch interaction through proximity-based hand input.pdf:pdf},
isbn = {9781450340823},
keywords = {Design,Human Factors,Measurement,Smartwatch.,design,human factors,measurement,smartwatch},
mendeley-groups = {Diss{\_}MyRelevant,First Author Papers,Cheesyfoot2go/Relevant Own Pubs,My Publications},
organization = {ACM},
pages = {2617--2624},
publisher = {ACM Press},
title = {{ProxiWatch: Enhancing smartwatch interaction through proximity-based hand input}},
url = {http://dl.acm.org/citation.cfm?doid=2851581.2892450 http://dx.doi.org/10.1145/2851581.2892450},
year = {2016}
}
@inproceedings{muller2015a,
abstract = {On-body user interfaces utilize the human's skin for both sensing input and displaying graphical output. In this paper, we present how the degree of freedom offered by the elbow joint, i.e., flexion and extension, can be leveraged to extend the input space of projective user interfaces. The user can move his hand towards or away from himself to browse through a multi-layer information space. We conducted a controlled experiment to investigate how accurately and efficiently users can interact in the space. The results revealed that the accuracy and efficiency of proximity-based interactions mainly depend on the traveling distance to the target layer while neither the hand side nor the direction of interaction have a significant influence. Based on our findings, we propose guidelines for designing on-body user interfaces.},
address = {New York, New York, USA},
author = {M{\"{u}}ller, Florian and Khalilbeigi, Mohammadreza and Dezfuli, Niloofar and {Sahami Shirazi}, Alireza and G{\"{u}}nther, Sebastian and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 3rd ACM Symposium on Spatial User Interaction - SUI '15},
doi = {10.1145/2788940.2788955},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{u}}ller et al. - 2015 - A Study on Proximity-based Hand Input for One-handed Mobile Interaction.pdf:pdf},
isbn = {9781450337038},
keywords = {Design,Human Factors,Measurement.},
mendeley-groups = {Cheesyfoot2go,Diss{\_}MyRelevant,First Author Papers,Cheesyfoot2go/Relevant Own Pubs,My Publications},
organization = {ACM},
pages = {53--56},
publisher = {ACM Press},
title = {{A Study on Proximity-based Hand Input for One-handed Mobile Interaction}},
url = {http://dl.acm.org/citation.cfm?doid=2788940.2788955},
year = {2015}
}
@inproceedings{Muller2015b,
address = {New York, New York, USA},
author = {M{\"{u}}ller, Florian and Dezfuli, Niloofar and M{\"{u}}hlh{\"{a}}user, Max and Schmitz, Martin and Khalilbeigi, Mohammadreza},
booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct - MobileHCI '15},
doi = {10.1145/2786567.2794314},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{u}}ller et al. - 2015 - Palm-based Interaction with Head-mounted Displays.pdf:pdf},
isbn = {9781450336536},
keywords = {Design,Head-mounted Displays,Human Factors},
mendeley-groups = {Cheesyfoot2go,Diss{\_}MyRelevant,First Author Papers,Cheesyfoot2go/Relevant Own Pubs,My Publications},
pages = {963--965},
publisher = {ACM Press},
title = {{Palm-based Interaction with Head-mounted Displays}},
url = {http://dl.acm.org/citation.cfm?doid=2786567.2794314},
year = {2015}
}
@inproceedings{Dezfuli2012,
abstract = {User input on television (TV) typically requires a mediator device, such as a handheld remote control. While being a well-established interaction paradigm, a handheld device has serious drawbacks: it can be easily misplaced due to its mobility and in case of a touch screen interface, it also requires additional visual attention. Emerging interaction paradigms like 3D mid-air gestures using novel depth sensors, such as Microsoft's Kinect, aim at overcoming these limitations, but are known to be e.g. tiring. In this paper, we propose to leverage the palm as an interactive surface for TV remote control. Our contribution is three-fold: (1) we explore the conceptual design space in an exploratory study. (2) Based upon these results, we investigate the effectiveness and accuracy of such an interface in a controlled experiment. And (3), we contribute PalmRC: an eyes-free, palm-surface-based TV remote control, which in turn is evaluated in an early user feedback session. Our results show that the palm has the potential to be leveraged for device-less and eyes-free TV remote interaction without any third-party mediator device.},
address = {New York, New York, USA},
author = {Dezfuli, Niloofar and Khalilbeigi, Mohammadreza and Huber, Jochen and M{\"{u}}ller, Florian and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Proceedings of the 10th European conference on Interactive tv and video - EuroiTV '12},
doi = {10.1145/2325616.2325623},
file = {:C$\backslash$:/Users/Flo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dezfuli et al. - 2012 - PalmRC imaginary palm-based remote control for eyes-free television interaction.pdf:pdf},
isbn = {9781450311076},
keywords = {TV,alternative remote control,device-less,direct touch,eyes-free,input,memory,non-visual,omnipresent},
mendeley-groups = {Cheesyfoot2go,MobileHCI Woprkshop,My Publications,CHI 2014,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
month = {jul},
organization = {ACM},
pages = {27},
publisher = {ACM Press},
title = {{PalmRC: imaginary palm-based remote control for eyes-free television interaction}},
url = {http://dl.acm.org/citation.cfm?doid=2325616.2325623 http://dl.acm.org/citation.cfm?id=2325616.2325623},
year = {2012}
}
@inproceedings{dezfuli2012couchtv,
author = {Dezfuli, Niloofar and Pavlakis, Manolis and M{\"{u}}ller, Florian and Khalilbeigi, Mohammadreza and M{\"{u}}hlh{\"{a}}user, Max},
booktitle = {Bridging People, Places {\&} Platforms. Adjunct Proceedings. 10th European Interacive TV},
isbn = {978-3-00-038715-9},
mendeley-groups = {My Publications,Cheesyfoot2go/Other Own Pubs,Diss{\_}myOther},
pages = {96--99},
title = {{Leveraging the Spatial Information of Viewers for Social Interactive Televion Systems}},
url = {https://lirias.kuleuven.be/bitstream/123456789/350723/3/AdjProc{\_}EuroITV2012.pdf},
year = {2012}
}
